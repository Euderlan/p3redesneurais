# Otimiza√ß√£o de Hiperpar√¢metros de MLPs usando Algoritmos Gen√©ticos

## üìã Sobre o Projeto

Este trabalho investiga a aplica√ß√£o de **Algoritmos Gen√©ticos (GA)** para otimiza√ß√£o de hiperpar√¢metros em **Multi-Layer Perceptrons**, comparando diferentes estrat√©gias evolutivas com uma abordagem baseline tradicional.

### üéØ Objetivos Principais

- Investigar a efic√°cia dos Algoritmos Gen√©ticos na otimiza√ß√£o de hiperpar√¢metros de MLPs
- Comparar diferentes configura√ß√µes de GA com uma abordagem baseline
- Avaliar o trade-off entre melhoria de performance e custo computacional
- Fornecer diretrizes pr√°ticas para aplica√ß√£o de GAs em problemas similares

## üî¨ Metodologia

### Dataset
- **Tipo**: Sint√©tico de classifica√ß√£o bin√°ria
- **Amostras**: 1.000 inst√¢ncias
- **Features**: 20 atributos (10 informativos, 5 redundantes)
- **Divis√£o**: 60% treino, 20% valida√ß√£o, 20% teste

### Hiperpar√¢metros Otimizados

| Par√¢metro | Valores Poss√≠veis | Descri√ß√£o |
|-----------|-------------------|-----------|
| `learning_rate_init` | [0.0001, 0.001, 0.01, 0.1] | Taxa de aprendizado inicial |
| `hidden_layer_sizes` | [(50,), (100,), (50,50), (100,50)] | Arquitetura das camadas ocultas |
| `activation` | ['logistic', 'tanh', 'relu'] | Fun√ß√£o de ativa√ß√£o |
| `solver` | ['adam', 'sgd'] | Algoritmo de otimiza√ß√£o |
| `max_iter` | [50, 500] | N√∫mero m√°ximo de √©pocas |

### Configura√ß√µes Experimentais

| Experimento | Popula√ß√£o | Gera√ß√µes | Crossover | Muta√ß√£o | Descri√ß√£o |
|-------------|-----------|----------|-----------|---------|-----------|
| **Baseline** | - | - | - | - | Par√¢metros padr√£o MLPClassifier |
| **GA_Config1** | 30 | 25 | 0.7 | 0.2 | Popula√ß√£o pequena, converg√™ncia r√°pida |
| **GA_Config2** | 50 | 50 | 0.7 | 0.2 | Configura√ß√£o equilibrada |
| **GA_Config3** | 70 | 40 | 0.8 | 0.15 | Popula√ß√£o grande, alta coopera√ß√£o |
| **GA_Config4** | 40 | 60 | 0.6 | 0.3 | Alta explora√ß√£o, mais gera√ß√µes |

## üìä Principais Resultados

### Performance
- ‚úÖ **Melhoria consistente**: Todos os GAs superaram o baseline
- ‚úÖ **Melhor configura√ß√£o**: GA_Config3 com +5.6% no F1-score
- ‚úÖ **Melhoria m√©dia**: +4.2% no F1-score sobre baseline

### Custo Computacional
- ‚è±Ô∏è **Tempo baseline**: ~2.3 segundos
- ‚è±Ô∏è **Tempo GAs**: 15-68 segundos (7-30x mais lento)
- üíª **Trade-off**: Melhoria de performance vs custo computacional

### Hiperpar√¢metros Descobertos
Os GAs encontraram configura√ß√µes n√£o √≥bvias:
- Prefer√™ncia por arquiteturas de duas camadas
- Learning rates mais altos (0.01) em muitos casos
- Combina√ß√µes espec√≠ficas de solver + activation

## üöÄ Como Usar

### Pr√©-requisitos

```bash
pip install numpy pandas matplotlib scikit-learn deap
```

### Execu√ß√£o R√°pida

```python
# Clone o reposit√≥rio
git clone https://github.com/seu-usuario/ga-hyperparameter-optimization.git
cd ga-hyperparameter-optimization

# Execute o notebook
jupyter notebook evolutionary_algorithms.ipynb
```

### Estrutura do Projeto

```
‚îú‚îÄ‚îÄ evolutionary_algorithms.ipynb    # Notebook principal
‚îú‚îÄ‚îÄ README.md                              # Este arquivo  
```

### Exemplo de Uso

```python
# Configura√ß√£o b√°sica de um experimento GA
experimento = {
    'pop_size': 50,      # Tamanho da popula√ß√£o
    'ngen': 40,          # N√∫mero de gera√ß√µes
    'cxpb': 0.7,         # Taxa de crossover
    'mutpb': 0.2,        # Taxa de muta√ß√£o
}

# Executar otimiza√ß√£o
resultado = run_ga_experiment(**experimento)
print(f"Melhor F1-score: {resultado['f1_test']:.4f}")
```

## üìà Visualiza√ß√µes

O projeto inclui visualiza√ß√µes para:

- üìä **Evolu√ß√£o do fitness** ao longo das gera√ß√µes
- üîÑ **Compara√ß√£o de performance** entre configura√ß√µes
- ‚è∞ **An√°lise custo-benef√≠cio** (tempo vs melhoria)
- üéØ **Precis√£o vs Recall** para cada experimento
- üß¨ **Par√¢metros finais** descobertos pelos GAs

## üîç Insights Principais

### Quando Usar GAs
‚úÖ **Recomendado quando:**
- Performance do modelo √© cr√≠tica
- Recursos computacionais s√£o adequados
- Busca exaustiva √© invi√°vel
- Solu√ß√µes inovadoras s√£o desejadas

‚ùå **N√£o recomendado quando:**
- Tempo √© limitado (prototipagem)
- Recursos computacionais restritos
- Baseline j√° atende requisitos

### Configura√ß√µes Recomendadas

| Cen√°rio | Popula√ß√£o | Gera√ß√µes | Tempo Esperado |
|---------|-----------|----------|----------------|
| **Desenvolvimento r√°pido** | 20-30 | 15-25 | 10-20s |
| **Produ√ß√£o equilibrada** | 40-50 | 30-50 | 30-60s |
| **Performance m√°xima** | 60-80 | 40-60 | 60-120s |

## üéì Fundamenta√ß√£o Te√≥rica

### Algoritmos Gen√©ticos
- Inspirados na evolu√ß√£o biol√≥gica
- Operadores: sele√ß√£o, crossover, muta√ß√£o
- Explora√ß√£o inteligente do espa√ßo de busca
- Robustos a √≥timos locais

### Hyperparameter Tuning
- Grid Search vs Random Search vs M√©todos Avan√ßados
- Import√¢ncia da valida√ß√£o cruzada
- Trade-off exploration vs exploitation

## üìö Refer√™ncias Principais

1. **Bergstra, J., & Bengio, Y.** (2012). Random search for hyper-parameter optimization. *JMLR*.
2. **Holland, J. H.** (1992). Adaptation in natural and artificial systems. *MIT Press*.
3. **Eiben, A. E., & Smith, J. E.** (2015). Introduction to evolutionary computing. *Springer*.
4. **Snoek, J., et al.** (2012). Practical bayesian optimization of machine learning algorithms. *NIPS*.
5. **Feurer, M., & Hutter, F.** (2019). Hyperparameter optimization. *Automated ML*.

## üîß Tecnologias Utilizadas

- **Python 3.7+**: Linguagem principal
- **scikit-learn**: MLPClassifier e m√©tricas
- **DEAP**: Framework de algoritmos evolutivos
- **NumPy**: Opera√ß√µes num√©ricas
- **Pandas**: Manipula√ß√£o de dados
- **Matplotlib**: Visualiza√ß√µes

## üìà Resultados Detalhados

### M√©tricas de Performance

| Configura√ß√£o | F1-Score | Precis√£o | Recall | Tempo (s) | Melhoria |
|--------------|----------|----------|--------|-----------|----------|
| Baseline | 0.8654 | 0.8523 | 0.8789 | 2.3 | - |
| GA_Config1 | 0.8923 | 0.8834 | 0.9015 | 15.7 | +3.1% |
| GA_Config2 | 0.9087 | 0.8978 | 0.9201 | 42.1 | +5.0% |
| GA_Config3 | **0.9134** | **0.9023** | **0.9248** | 67.8 | **+5.6%** |
| GA_Config4 | 0.8998 | 0.8889 | 0.9112 | 58.3 | +4.0% |

## üöß Limita√ß√µes e Trabalhos Futuros

### Limita√ß√µes Identificadas
- Dataset sint√©tico de complexidade limitada
- Espa√ßo de hiperpar√¢metros restrito
- An√°lise de execu√ß√£o √∫nica (sem robustez estat√≠stica)
- Aus√™ncia de compara√ß√£o com outros m√©todos

### Trabalhos Futuros
- Valida√ß√£o em datasets reais complexos
- Compara√ß√£o com Bayesian Optimization
- An√°lise estat√≠stica com m√∫ltiplas execu√ß√µes
- Otimiza√ß√£o multi-objetivo
- Paraleliza√ß√£o dos algoritmos


## üìÑ Licen√ßa

### **Reconhecimentos e Direitos Autorais**

**@autor:** ¬πEuderlan Freire - ¬≤Hissa B√°rbara - ¬≥Lucas Silva - Maria Clara. 
**@contato:** [¬≥computer.lucas2@gmail.com]  
**@data √∫ltima vers√£o:** 12 de junho de 2025  
**@vers√£o:** 1.0  
**@outros reposit√≥rios:** [URLs - apontem para os seus Gits AQUI]  
**@Agradecimentos:** Universidade Federal do Maranh√£o (UFMA), Professor Doutor Thales Levi Azevedo Valente, e colegas de curso.

### **Copyright/License**

Este material √© resultado de um trabalho acad√™mico para a disciplina **INTELIG√äNCIA ARTIFICIAL**, sob a orienta√ß√£o do professor **Dr. THALES LEVI AZEVEDO VALENTE**, semestre letivo **2025.1**, curso **Engenharia da Computa√ß√£o**, na **Universidade Federal do Maranh√£o (UFMA)**.

Todo o material sob esta licen√ßa √© software livre: pode ser usado para fins acad√™micos e comerciais sem nenhum custo. N√£o h√° papelada, nem royalties, nem restri√ß√µes de "copyleft" do tipo GNU. Ele √© licenciado sob os termos da **Licen√ßa MIT**, conforme descrito abaixo, e, portanto, √© compat√≠vel com a GPL e tamb√©m se qualifica como software de c√≥digo aberto. √â de dom√≠nio p√∫blico. Os detalhes legais est√£o abaixo. O esp√≠rito desta licen√ßa √© que voc√™ √© livre para usar este material para qualquer finalidade, sem nenhum custo. O √∫nico requisito √© que, se voc√™ us√°-los, nos d√™ cr√©dito.

### **Licen√ßa MIT**

Licenciado sob a Licen√ßa MIT. Permiss√£o √© concedida, gratuitamente, a qualquer pessoa que obtenha uma c√≥pia deste software e dos arquivos de documenta√ß√£o associados (o "Software"), para lidar no Software sem restri√ß√£o, incluindo sem limita√ß√£o os direitos de usar, copiar, modificar, mesclar, publicar, distribuir, sublicenciar e/ou vender c√≥pias do Software, e permitir pessoas a quem o Software √© fornecido a faz√™-lo, sujeito √†s seguintes condi√ß√µes:

Este aviso de direitos autorais e este aviso de permiss√£o devem ser inclu√≠dos em todas as c√≥pias ou partes substanciais do Software.

**O SOFTWARE √â FORNECIDO "COMO EST√Å", SEM GARANTIA DE QUALQUER TIPO, EXPRESSA OU IMPL√çCITA, INCLUINDO MAS N√ÉO SE LIMITANDO √ÄS GARANTIAS DE COMERCIALIZA√á√ÉO, ADEQUA√á√ÉO A UM DETERMINADO FIM E N√ÉO INFRING√äNCIA. EM NENHUM CASO OS AUTORES OU DETENTORES DE DIREITOS AUTORAIS SER√ÉO RESPONS√ÅVEIS POR QUALQUER RECLAMA√á√ÉO, DANOS OU OUTRA RESPONSABILIDADE, SEJA EM A√á√ÉO DE CONTRATO, TORT OU OUTRA FORMA, DECORRENTE DE, FORA DE OU EM CONEX√ÉO COM O SOFTWARE OU O USO OU OUTRAS NEGOCIA√á√ïES NO SOFTWARE.**

Para mais informa√ß√µes sobre a Licen√ßa MIT: https://opensource.org/licenses/MIT

## üìû Contato

**Autor**: [EUderlan Freire]
- üìß Email: [euderlan.freire@discente.ufma.br]




**‚≠ê Se este projeto foi √∫til, considere dar uma estrela!**

</div>
